{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99c5d707-ba08-4075-8697-c0ba91c0ecb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, top_k_accuracy_score\n",
    "import json\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "import argparse\n",
    "\n",
    "def save_csv_for_iteration(temp_dir, model_dir, split_percentage, iteration, df):\n",
    "    csv_file = os.path.join(temp_dir, f'{model_dir}_{split_percentage}_{iteration}.csv')\n",
    "    df.to_csv(csv_file, index=False)\n",
    "\n",
    "def find_last_iteration(temp_dir, model_dir, split_percentage):\n",
    "    for iteration in range(10, 0, -1):\n",
    "        csv_file = os.path.join(temp_dir, f'{model_dir}_{split_percentage}_{iteration}.csv')\n",
    "        if os.path.exists(csv_file):\n",
    "            return iteration, pd.read_csv(csv_file)\n",
    "    return 0, pd.DataFrame()\n",
    "\n",
    "def calculate_mean_std(df):\n",
    "    metric_columns = ['Accuracy', 'Top-1%', 'Top-3%', 'Top-5%', 'Precision', 'Recall', 'F1 Score', 'Time Taken (s)']\n",
    "    aggregated_results = {}\n",
    "    for col in metric_columns:\n",
    "        if col in df:\n",
    "            aggregated_results[f'Mean {col}'] = round(df[col].mean(), 2)\n",
    "            aggregated_results[f'Std {col}'] = round(df[col].std(), 2)\n",
    "    return pd.DataFrame([aggregated_results])\n",
    "\n",
    "def save_final_csv_with_aggregates(results_dir, model_dir, split_percentage, final_results_df):\n",
    "    aggregated_results_df = calculate_mean_std(final_results_df)\n",
    "    final_csv_file = os.path.join(results_dir, f'{model_dir}_{split_percentage}_10.csv')\n",
    "    aggregated_results_df.to_csv(final_csv_file, index=False)\n",
    "    print(f\"Final aggregated results saved to {final_csv_file}\")\n",
    "\n",
    "def classify_and_save_results(encodings_dir, temp_dir, results_dir, model_dir, split_percentage):\n",
    "    features_path = os.path.join(encodings_dir, model_dir, 'encoded_images.npy')\n",
    "    labels_path = os.path.join(encodings_dir, model_dir, 'labels.npy')\n",
    "    features = np.load(features_path, allow_pickle=True)\n",
    "    labels = np.load(labels_path, allow_pickle=True)\n",
    "    scaler = StandardScaler()\n",
    "    features = scaler.fit_transform(features)\n",
    "    svm = SVC(kernel='linear', probability=True)\n",
    "    start_iteration, final_results_df = find_last_iteration(temp_dir, model_dir, split_percentage)\n",
    "    stratified_split = StratifiedShuffleSplit(n_splits=3, test_size=(1 - split_percentage / 100), random_state=42)\n",
    "    for iteration, (train_idx, test_idx) in enumerate(stratified_split.split(features, labels), start=start_iteration):\n",
    "        print(f\"Iteration {iteration+1}/3\")\n",
    "        X_train, X_test = features[train_idx], features[test_idx]\n",
    "        y_train, y_test = labels[train_idx], labels[test_idx]\n",
    "        start_time = time.time()\n",
    "        svm.fit(X_train, y_train)\n",
    "        y_pred = svm.predict(X_test)\n",
    "        y_prob = svm.predict_proba(X_test)\n",
    "\n",
    "        n_classes = len(np.unique(labels))\n",
    "        results = {\n",
    "            'Iteration': iteration + 1,\n",
    "            'Model': model_dir,\n",
    "            'Split Percentage': split_percentage,\n",
    "            'Accuracy': round(accuracy_score(y_test, y_pred) * 100, 2),\n",
    "            'Precision': round(precision_score(y_test, y_pred, average='weighted') * 100, 2),\n",
    "            'Recall': round(recall_score(y_test, y_pred, average='weighted') * 100, 2),\n",
    "            'F1 Score': round(f1_score(y_test, y_pred, average='weighted') * 100, 2),\n",
    "            'Time Taken (s)': time.time() - start_time\n",
    "        }\n",
    "\n",
    "        # Add Top-K metrics only for multi-class classification\n",
    "        if n_classes > 2:\n",
    "            results['Top-1%'] = round(top_k_accuracy_score(y_test, y_prob, k=1, labels=np.unique(labels)) * 100, 2)\n",
    "            results['Top-3%'] = round(top_k_accuracy_score(y_test, y_prob, k=3, labels=np.unique(labels)) * 100, 2) if n_classes > 3 else None\n",
    "            results['Top-5%'] = round(top_k_accuracy_score(y_test, y_prob, k=5, labels=np.unique(labels)) * 100, 2) if n_classes > 5 else None\n",
    "\n",
    "        final_results_df = pd.concat([final_results_df, pd.DataFrame([results])], ignore_index=True)\n",
    "        save_csv_for_iteration(temp_dir, model_dir, split_percentage, iteration + 1, final_results_df)\n",
    "    save_final_csv_with_aggregates(results_dir, model_dir, split_percentage, final_results_df)\n",
    "\n",
    "def cleanup_temp_folder(temp_dir):\n",
    "    for file in os.listdir(temp_dir):\n",
    "        file_path = os.path.join(temp_dir, file)\n",
    "        if file.endswith('.csv'):\n",
    "            os.remove(file_path)\n",
    "    print(\"All temporary CSV files deleted from temp folder.\")\n",
    "\n",
    "def combine_csv_files_for_model(results_dir, model_dir):\n",
    "    combined_df = pd.DataFrame()\n",
    "    for split_percentage in [70, 80, 90]:\n",
    "        csv_file = os.path.join(results_dir, f'{model_dir}_{split_percentage}_10.csv')\n",
    "        if os.path.exists(csv_file):\n",
    "            df = pd.read_csv(csv_file)\n",
    "            df.insert(0, 'Split', split_percentage)\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "    combined_csv_file = os.path.join(results_dir, f'{model_dir}.csv')\n",
    "    combined_df.to_csv(combined_csv_file, index=False)\n",
    "    print(f\"Combined CSV saved as {combined_csv_file}\")\n",
    "\n",
    "def main(proj_dir, encodings_dir, results_dir):\n",
    "    temp_dir = os.path.join(proj_dir, 'temp_results')\n",
    "    if not os.path.exists(temp_dir):\n",
    "        os.makedirs(temp_dir)\n",
    "    model_dirs = [d for d in os.listdir(encodings_dir) if os.path.isdir(os.path.join(encodings_dir, d))]\n",
    "    for model_dir in model_dirs:\n",
    "        print(f\"Processing model: {model_dir}\")\n",
    "        for split_percentage in [90, 80, 70]:\n",
    "            final_csv_file = os.path.join(results_dir, f'{model_dir}_{split_percentage}_10.csv')\n",
    "            if os.path.exists(final_csv_file):\n",
    "                print(f\"Results for {model_dir} with {split_percentage}% split already exist. Skipping.\")\n",
    "                continue\n",
    "            print(f\"Evaluating {split_percentage}-{100 - split_percentage} split\")\n",
    "            classify_and_save_results(encodings_dir, temp_dir, results_dir, model_dir, split_percentage)\n",
    "    cleanup_temp_folder(temp_dir)\n",
    "    for model_dir in model_dirs:\n",
    "        combine_csv_files_for_model(results_dir, model_dir)\n",
    "    print(\"Processing completed.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    parser = argparse.ArgumentParser(description='Classify images and save results using SVM.')\n",
    "    parser.add_argument('--proj_dir', type=str, required=True, help='Project directory path')\n",
    "    parser.add_argument('--encodings_dir', type=str, required=True, help='Directory path for encoded images')\n",
    "    parser.add_argument('--results_dir', type=str, required=True, help='Directory path to save results')\n",
    "    args = parser.parse_args()\n",
    "    main(args.proj_dir, args.encodings_dir, args.results_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d50489cc-d439-42aa-82e9-51adee9b0186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define arguments directly\n",
    "proj_dir = \"path/to/project/directory\"\n",
    "encodings_dir = \"path/to/encodings/directory\"\n",
    "results_dir = \"path/to/results/directory\"\n",
    "\n",
    "# Call the main function with these arguments\n",
    "main(proj_dir, encodings_dir, results_dir)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
